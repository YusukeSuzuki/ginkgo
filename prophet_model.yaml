---
# user data tree
user_variables:
  - op_device: &op_device '/cpu:0'
# graph data tree
# todo: create linear class
# todo: create dropout class
# todo: create avgpool class
# input: [9,9,148]
root: !root
  nodes_required: ['root']
  nodes:
    - !with
      device_scope: '/gpu:0'
      nodes:
      - !with
        variable_scope: conv1
        nodes:
        - !conv2d
          { nid: t_c1, source: root, width: 9, height: 9, kernels_num: 600, b_init: 1e-7 }
        #- !relu { nid: c1, features: t_c1 }
        - !tanh { nid: c1, x: t_c1 }
      - !with
        variable_scope: conv2
        nodes:
        - !conv2d
          { nid: t_c2, source: c1, width: 7, height: 7, kernels_num: 900, b_init: 1e-7 }
        #- !relu { nid: c2, features: t_c2 }
        - !tanh { nid: c2, x: t_c2 }
      - !with
        variable_scope: conv3
        nodes:
        - !conv2d
          { nid: t_c3, source: c2, width: 5, height: 5, kernels_num: 1200, b_init: 1e-7 }
        #- !relu { nid: c3, features: t_c3 }
        - !tanh { nid: c3, x: t_c3 }
      - !with
        variable_scope: maxpool1
        nodes:
        - !max_pool_2x2
          {nid: mp1, source: c3}
      - !with
        variable_scope: conv4
        nodes:
        - !conv2d
          { nid: t_c4, source: mp1, width: 3, height: 3, kernels_num: 1600, b_init: 1e-7 }
        #- !relu { nid: c4, features: t_c4 }
        - !tanh { nid: c4, x: t_c4 }
      - !with
        variable_scope: conv5
        nodes:
        - !conv2d
          { nid: t_c5, source: c4, width: 3, height: 3, kernels_num: 1600, b_init: 1e-7 }
        #- !relu { nid: c5, features: t_c5 }
        - !tanh { nid: c5, x: t_c5 }
      - !with
        variable_scope: maxpool2
        nodes:
        - !max_pool_2x2
          {nid: mp2, source: c5}
      - !with
        variable_scope: conv6
        nodes:
        - !conv2d
          { nid: t_c6, source: mp2, width: 3, height: 3, kernels_num: 1600, b_init: 1e-7 }
        #- !relu { nid: c6, features: t_c6 }
        - !tanh { nid: c6, x: t_c6 }
      - !with
        variable_scope: conv7
        nodes:
        - !conv2d
          { nid: t_c7, source: c6, width: 3, height: 3, kernels_num: 1200, b_init: 1e-7 }
        #- !relu { nid: c7, features: t_c7 }
        - !tanh { nid: c7, x: t_c7 }
      - !with
        variable_scope: conv8
        nodes:
        - !conv2d
          { nid: t_c8, source: c7, width: 3, height: 3, kernels_num: 900, b_init: 1e-7 }
        #- !relu { nid: c8, features: t_c8 }
        - !tanh { nid: c8, x: t_c8 }
      - !with
        variable_scope: avgpool1
        nodes:
        - !avg_pool
          { nid: ap1, value: c8, width: 3, height: 3}
      - !with
        variable_scope: linear1
        nodes:
        - !linear
          { nid: t_l1, name: l1, source: ap1, b_init: 1e-15, length: 600}
        - !tanh
          { nid: tt_l1, name: tanh1, x: t_l1}
        - !dropout
          { nid: l1, x: tt_l1, keep_prob: 0.25 }
      - !with
        variable_scope: linear2
        nodes:
        - !linear
          { nid: l2, name: l2, source: l1, b_init: 1e-15, length: 2}
        - !softmax { nid: out, name: out, logit: l2 }
    - !with
      variable_scope: train
      device_scope: '/gpu:0'
      tags: [train]
      nodes:
      - !placeholder
        { nid: label, name: label, tag: train, dtype: tf.float32, shape: [null,2]}
      - !placeholder
        { nid: turn_weight, name: turn_weight,
          tag: train, dtype: tf.float32, shape: [null,1]}
      - !prophet_loss
          { nid: p_loss, tag: train,
            source1: out, source2: label, source3: turn_weight }
      - !adam_optimizer {tag: train, name: optimizer, source: p_loss, val: 1e-4, takelog: true}
    - !with
      variable_scope: log
      device_scope: '/cpu:0'
      tags: [train, log]
      nodes:
      - !reduce_mean
        {nid: loss_mean, source: p_loss, dims: [1]}
      - !scalar_summary
        {summary_tag: 'loss', source: loss_mean}

